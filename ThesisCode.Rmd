---
title: "Lewis' Thesis Code"
author: "Lewis Hakam"
date: "10/3/2023"
output: html_document
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#personal access token if needed: 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
#Data retrieval and manipulation
library(move)
library(sp)
library(moveVis)
#organizating, filtering, cleaning data
library(plyr)
library(dplyr) #deleted and re installed rlang
library(stats)
library(devtools) #deleted and re installed htmltools
library(lutz) #time zone lookup
library(solaR) #calculate solar time
library(lubridate)
find_mode <- function(x) {
  u <- unique(x)
  tab <- tabulate(match(x, u))
  u[tab == max(tab)]
} #no built in function for mode in R so I got this one from the web. 
library(data.table)
#Movement models
library(migrateR) #could not build vignettes. Also used force = T and updated some packages.
library(adehabitatLT)
#static map
library(ggplot2)
library(sf)
library(tmap)
wgs84<-CRS("+proj=longlat +datum=WGS84") #GCS in WGS 1984
azim_orign = CRS("+proj=aeqd +lat_0=24.43 +lon_0=-82.74 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs") #PCS in custom azimuthal equidistant projection. estiated middle point of the data visually with google maps
data(World) #world data with country polygons needed for mapping
world_sf<-st_transform(World, azim_orign) #projected world data
plotshit<-function(y) {
  ggplot(y) +
    geom_sf(data = world_sf, fill = "white") +
    geom_sf(size = 1, aes(color = year)) +
    coord_sf(datum = st_crs(azim_orign), xlim = c(-4000000, 3000000), ylim = c(3500000, -2500000)) +
    theme(legend.position = "bottom", legend.text = element_text(size = 7)) +
    labs(color = "year") +
    ggtitle(paste0(y$trackId))
} #function for batch plotting in a for loop

#data anlaysis
library(PerformanceAnalytics) #correlations and EDA
library(FactoMineR) #PCA biplots
library(hopkins) #hopkins statistic for clustering potential
library(cluster) #linkage methods 
library(stats) #PCA, HCA and dendrogram
library(NbClust)#optimal clusterss
library(dendextend) #modify dendrogram
library(ComplexHeatmap) #heatmaps
library(RColorBrewer) #color palette customization 
library(vegan) #PERMANOVA
```

## Introduction

Hey there! If you are viewing this article, you are interested in how I analyzed osprey tracking data for my final thesis, completed in Spring 2024. I will guide through a step by step process. I have used R Markdown, which may be new for you. This document will not go over the nuances I used to code the Markdown file. For simplicity and privacy, not all code lines are shown in the Rmarkdown output. If you want to see the entire code script, you will need to open the RStudio project, accessible through the Osprey Shared Drive or by contacting me directly. I have done my best to annotate my code for easy interpret ability.


## Packages
Here is a list of packages and functions in the order of their first appearance that I used followed by custom functions and R objects.You will likely have to use the function install.packages ("Package Name") before you can access packages using the library (Package Name) function. I had a few instances where I had supporting packages downloaded, but they were not up-to-date nor could I force them to update. For these packages I had to go into this PC < documents < R and locally delete the packages that were not updating and then re-install them. Many of these packages have dependencies (they require other packages) so do not be alarmed if download takes a while. The dependencies are also downloading. Lastly, some packages are not from CRAN,rather they are from personal repositories on github or from Bioconductor These packages require special download code. To download packages in github repos, you need to use the install_github("username/repo/package file name",) from the 'devtools' package. For Bioconductor packages you need to use the install("package name") function from the 'BioManager' package.
* CRAN: install.packages() from base R *
* BioConductor: install() from BioManager **
* Personal Repositories: install_github() from devtools ***

```{r, eval=FALSE}
library(move) # download and retrieve movement data and characteristics *
library(sp) # Create sp spatial objects *
library(moveVis) # transform dataframes into move objects ***
library(plyr) # apply a function to a list *
library(dplyr) # manipulate dataframes and filter data *
library(stats) # some statistic tools plus HCA function *
library(lutz) # Determine if there was daylight during a GPS fix *
library(solaR) # Calculate local solar time *
library(lubridate) # Manipulate time/date formats *
library(data.table) # Work with data tables *
library(migrateR) # Calculate start/end dates of migration **
library(adehabitatLT) # Find fpt and displacement *
library(ggplot2) # graphing/mapping *
library(sf) # sf spatial objects in R for mapping *
library(tmap) # world country shapefiles *
library(PerformanceAnalytics) # Correlations and EDA *
library(FactoMineR) # PCA biplots *
library(hopkins) # Hopkins statistic for clustering potential *
library(cluster) # Linkage methods *
library(NbClust)# Optimal clusterss *
library(dendextend) # Modify dendrogram *
library(ComplexHeatmap) # Heatmaps **
library(RColorBrewer) # Color palette customization *
library(vegan) # PERMANOVA *


wgs84<-CRS("+proj=longlat +datum=WGS84") # GCS
azim_orign = CRS("+proj=aeqd +lat_0=24.43 +lon_0=-82.74 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs") # Azimuthal Equidistant PCS
data(World) # Country Shapefiles
world_sf<-st_transform(World, azim_orign) #Country Shapefiles projected with custom PCS
find_mode <- function(x) {
  u <- unique(x)
  tab <- tabulate(match(x, u))
  u[tab == max(tab)]
} # Mode function
plotshit<-function(y) {
  ggplot(y) +
    geom_sf(data = world_sf, fill = "white") +
    geom_sf(size = 1, aes(color = year)) +
    coord_sf(datum = st_crs(azim_orign), xlim = c(-4000000, 3000000), ylim = c(3500000, -2500000)) +
    theme(legend.position = "bottom", legend.text = element_text(size = 7)) +
    labs(color = "year") +
    ggtitle(paste0(y$trackId))
} # Batch Map raw data by individual bird and year function
```


## Downloading and Filtering Tracking Data

#### Downloading and Exploring Data From Movebank
First, If you do not have a Movebank account, you must make a free account before you can access any of the data. Even after you make an account, not all data is available for download. There are three levels of privacy: downloadable (orange), tracks and study present with no download (blue), and studies where no tracks can be seen and no download is available (grey). More information about navigating Movebank can be found on the Movebank website: <https://www.movebank.org/cms/movebank-main>

I pulled data from three sources:

1. Bierregaard East Coast Osprey Tracking - open-access download (permission needed to use in publications)
2. Barb Jensen's Michigan Osprey Tracks - open-access download (permission needed to use in publications)
3. *The Montana osprey Satellite Tracking Program - Permission-access only*

To pull data from movebank you will use the 'move' package. Before you can pull data with the move package you will need to create an object called loginStored which contains your login info. I have not included the actual code since I do not want to give out my password. Your code will look something like this:
```{r, eval=FALSE}
loginStored <- movebankLogin(username = "UserName", password = "Password")
```

```{r, echo=FALSE}
loginStored <- movebankLogin(username = "lhaka2", password = "!ShamaJ2016!")
```

Next you will download the Movebank study synopsis and summary tables. Finding studies is easiest using the interactive map on the Movebank Website. It is possible to search for studies within R, but you will save yourself some time using the website.The synopsis can provide details on how many individuals were tracked, the time frame tracking occurred, the type of device used, demographic information (sex, age, etc.), and permission/privacy restrictions. The summary table will provide a summary of each individual tracked per device. This means that some individuals may have multiple entries in a summary table to account for different tracking mechanisms. We can use the summary table info to partially fill out demographic information and determine how many individuals were tracked using GPS or GPS/GSM devices. I kept a running document of individuals with their demographic and geographic information that will come in handy later on. 

```{r, warning=FALSE}
#download Bierregaard data Synopsis
getMovebankStudy(study ="Osprey Bierregaard North and South America", login = loginStored)
#download Bierregaard summary table
Bierregaard_Osprey_summary<-getMovebankReferenceTable(study ="Osprey Bierregaard North and South America", login = loginStored, allAttributes = FALSE)
#Explore sensor attributes and associated codes. We only want a summary of individuals with GPS tracks.
getMovebankSensorsAttributes(study="Osprey Bierregaard North and South America",login=loginStored) #sensor_type_id for GPS that we will need is 653. 7842954 is the GPS engineering data and 82798	is Argos data. Filter the summary table to keep only individuals with the sensor_type_id of 653.
Bierregaard_Osprey_summary<-filter(Bierregaard_Osprey_summary,
                                   Bierregaard_Osprey_summary$sensor_type_id == 653)
#Create a table of sex and life stage for a brief overview of how many adults/juveniles of male and female exist within the dataset.
table(Bierregaard_Osprey_summary$animal_life_stage, Bierregaard_Osprey_summary$animal_sex)
# While this table is helpful at a glance, I found I could fill in life stage by looking at the birth date if include and comparing it with the tracking year. I also consulted the comments for clues to age and sex. I did this by going to the environment pane and clicking on the filtered summary table to open the full table. 
```

```{r, warning=FALSE}
#Barb Jensen's data
getMovebankStudy(study ="Pandion haliaetus Osprey - SouthEast Michigan", login = loginStored)
Jensen_Osprey_summary<-getMovebankReferenceTable(study ="Pandion haliaetus Osprey - SouthEast Michigan", 
                                                 login = loginStored, allAttributes = FALSE)
Jensen_Osprey_summary<-filter(Jensen_Osprey_summary, Jensen_Osprey_summary$sensor_type_id == 653)
table(Jensen_Osprey_summary$animal_sex) #22 individuals total, 11 females, 8 males, and 3 unknown
```

The summary tables give me an idea of the total number of individuals in each study and the sex and age of each individual. However, it does not tell me the number of fall migrations and whether those migrations were complete or not, or if the individual even started migration. Age and sex data may also be missing. Sometimes sex is unknown, especially for juveniels, which are not sexually dimorphic. 

The data sets are really large, so I filtered the data to make it easier to work with and plot. I will remove:
* individuals with sampling frequencies courser than 1-hour (using mode and median)
* GPS fixes outside of July-November (7-11) when osprey are at wintering, natal/breeding sites, or on spring migration
* erroneous points that don't meet a defined biological/practical threshold.

```{r, warning=FALSE, message=FALSE}
#Download data from Movebank for GPS tracked individuals.This takes some time, but downloads data directly from Movebank. From the summary data, I filtered out only GPS tracked individuals. When downloading movebank data, I can specify which individuals I want in my dataset using animalName = (list of animal local identifiers)
Bierregaard_Osprey<-getMovebankData(study ="Osprey Bierregaard North and South America",
                                    animalName = c(Bierregaard_Osprey_summary$animal_local_identifier),
                                    login = loginStored, removeDuplicatedTimestamps=TRUE) 
#Get the time between consecutive locations using the move package
list_Bierr<-timeLag(Bierregaard_Osprey, units = "hours")
#lapply function applies a function to a list.Each individual within the data set has a median or mode timelag of 1 hour or finer. I used median/mode instead of average since its inevitable that some points were missed (either because the GPS was set to turn off an night, the GPS was turned off when the bird reached a certain location, the data was collected in bursts in the case of GSM, or because the GPS could not get signal)
sapply(list_Bierr, find_mode) 
sapply(list_Bierr, median)
#make into a data frame so I can easily filter, plot, and manipulate the data.
Bierregaard_Osprey_DF<-as.data.frame(Bierregaard_Osprey)
#I don't need to convert timestamp to local time since its already in local time apparently
#Extract month data for filtering
Bierregaard_Osprey_DF$month<-month(ymd_hms(Bierregaard_Osprey_DF$timestamp))
#Extract year data for plotting later
Bierregaard_Osprey_DF$year<-year(ymd_hms(Bierregaard_Osprey_DF$timestamp))
#remove rows with NA values for the next step
Bierregaard_Osprey_DF<-Bierregaard_Osprey_DF[!is.na(Bierregaard_Osprey_DF$heading),]
#filter erroneous points: Erroneous points are those with unrealistically high speed and turning angle (course). For course (sometimes mistakenly referred to as heading) we will look at the 90th percentile of points as suggested by Gupte et al., 2021. Course is measured as the angle from magnetic north (clockwise).A course of 0 indicates no movement. For speed I used Kerlinger 1989 to determine that the maximum recorded flight speed of an osprey was 33.4 meters/second.
quantile(Bierregaard_Osprey_DF$heading, probs = 0.9) #got 228
Bierregaard_Osprey_DF_Filter<-filter(Bierregaard_Osprey_DF, ground_speed <= 33.4 & heading < 239)
#Filter data - removed timestamps from December through June (keep months 7-11)
Bierregaard_Osprey_Data <- Bierregaard_Osprey_DF_Filter %>%
  filter(sensor_type_id == 653 & month %in% c(6:12))
```

```{r, warning=FALSE, message=FALSE}
#All individuals are tracked via GPS so no need to specify which individuals to download. 
Jensen_Osprey<-getMovebankData(study ="Pandion haliaetus Osprey - SouthEast Michigan",
                                    login = loginStored, removeDuplicatedTimestamps=TRUE) 
#explore sampling frequencies using time lag
list_Jens<-timeLag(Jensen_Osprey, units = "hours")
sapply(list_Jens, find_mode)
sapply(list_Jens, median) #X82186.Humphries_Rachel and X82190.Fenton_Aldo have courser frequencies than what I am looking for so I will remove these individuals after mapping. 
Jensen_Osprey_DF<-as.data.frame(Jensen_Osprey)
Jensen_Osprey_DF$month<-month(ymd_hms(Jensen_Osprey_DF$timestamp))
Jensen_Osprey_DF$year<-year(ymd_hms(Jensen_Osprey_DF$timestamp))
Jensen_Osprey_DF<-Jensen_Osprey_DF[!is.na(Jensen_Osprey_DF$heading),]
#Filter data - removed timestamps from December through June (keep months 7-11)
quantile(Jensen_Osprey_DF$heading, probs = 0.9) #got 218
Jensen_Osprey_DF_Filter<-filter(Jensen_Osprey_DF, ground_speed <= 33.4 & heading < 227)
Jensen_Osprey_Data <- Jensen_Osprey_DF_Filter %>%
  filter(sensor_type_id == 653 & month %in% c(6:12))
#remove the two individuals that were tracked at courser sampling frequencies than needed.
Jensen_Osprey_Data$trackId<-as.character(Jensen_Osprey_Data$trackId)
remove<-c("X82190.Fenton_Aldo", "X82186.Humphries_Rachel")
Jensen_Osprey_Data<-Jensen_Osprey_Data[!(Jensen_Osprey_Data$trackId %in% remove),]
unique(Jensen_Osprey_Data$trackId)
```

To map the data from each study, I will use the 'ggplot', which relys on 'sf' spatial objects for mapping purposes. I will map each individual bird, with tracks color-coded by year. This requires the custom 'plotshit' function and a for loop. Data on the background world countries is from the 'tmap' and data will be projected using a custom aziumthal equidistant projection. The actual projection used to map data is not all that important at the moment since we are not measuring anything, however the projection will be important later on. The projection was defined by using google maps to estimate the center of all of my data. 

```{r, fig.show="hold", out.width="10%"}
#Spatially reference the Bierregaard data
Bierregaard_Osprey_Data_sf<-st_as_sf(x=Bierregaard_Osprey_Data, 
                                     coords = c("location_long.1", "location_lat.1"), crs = wgs84)
Bierregaard_Osprey_Data_sf<-st_transform(Bierregaard_Osprey_Data_sf, azim_orign)
#to color code year, ggplot needs year to be a factor data type. 
Bierregaard_Osprey_Data_sf$year<-as.factor(Bierregaard_Osprey_Data_sf$year) 
#batch map the GPS points for each individual using ggplot
names<-unique(Bierregaard_Osprey_Data_sf$trackId)

for (i in names) {
  y = filter(Bierregaard_Osprey_Data_sf, trackId == i)
  pws<-plotshit(y)
  print(pws)
}
#I will remove individuals that did not start migration or were tracked in 2007 (the tracks from this year are very thin: "Pearl 2013", "Rafael 2009","Luke 2007", "Aster 2017", "Chester 2014", "Felix 2007", "Claws 2007", "Claws 2008" "Mackenzie 2013", "Trepassey 2016", "Tucker 2011", "Jocelyn 2016", 

#I will also remove tracks from specific years for some individuals since those migrations were not started or skipped (juveniles spend 18 months in wintering grounds during their first winter): "Rammie 2013", "Snowy 2012", "Thatcher 2011", "Penelope 2009", "Buck 2010", "Belle 2011", "Flow 2015", "Art 2013", "Artoo 2014", "Crabby 2015", "Borealis 2018", "Daphne 2017", "Weber 2014", "Nick 2017", "Ron 2015", "Woody 2015", "Rodney 2014"
```

```{r, fig.show="hold", out.width="10%"}
#Give Jensen data spatial reference
Jensen_Osprey_Data_sf<-st_as_sf(x=Jensen_Osprey_Data, 
                                coords = c("location_long.1", "location_lat.1"), crs = wgs84)
Jensen_Osprey_Data_sf<-st_transform(Jensen_Osprey_Data_sf, azim_orign)
Jensen_Osprey_Data_sf$year<-as.factor(Jensen_Osprey_Data_sf$year)
#batch map the GPS points for each individual using ggplot
names<-unique(Jensen_Osprey_Data_sf$trackId)
names
for (i in names) {
  y = filter(Jensen_Osprey_Data_sf, trackId == i)
  pws<-plotshit(y)
  print(pws)
}

#Remove individuals that did not migrate: "X586.Brighton_Barb 2015", "X934.Kensington.Pebbles 2017"

#Remove tracks for years where migration did not happend: "X423.Humphries_DTE_Ozzie 2015", "X139005.Monroe.Julie 2017"
```

From the plots, I can get an idea of how many fall migration events occurred for each bird. Migration events will be analyzed separately from each other. I can also tell if some individuals were juveniles during their first migration as juveniles spend 18 months wintering and return to breeding areas at three-years old. Birds with years that were clearly spent in wintering habitats during the predicted migration period were classified as juveniles during their first recorded previous migration. Finally, I can remove migration events that did not happen. Some birds never left their breeding/natal grounds, which means they cannot be used in my analysis. I filter these birds out later along with points outside of the fall migration period after I combine all of my datasets.   


#### Downloading and Exploring Data From the Illinois Osprey Program
This data can be obtained from the Osprey Shared drive. I have uploaded a pre-filtered version to my Github repository. This means that I can draw the data directly from the repository link while working in the project. I have explored this data in the past and I know which individuals I should keep. I also know all individuals are GPS tracked and that only GPS points are included in the data set. I will still need to filter by month and take out erroneous points, but that is about all I have to do. I have plotted the data on a single map for reference. 

Load in data and keep only individuals that started migration.
```{r, message=FALSE}
#The dataset is on github, so it is part of the project file
PTT2014to2022Compiled <- read_csv("PTT2014to2022Compiled.csv")
IL_OspreyData<-as.data.frame(PTT2014to2022Compiled)
#I explored this data earlier in the year, and determined these were the individuals that started migration.
keep<-c("2016_35D_14700", "2017_47D_171072", "2019_69D_180325", "2022_27R_220453", "2022_26R_234626", "2020_06R_202512", "2017_44D_171073", "2014_14D_139465", "2020_73D_202511")
IL_OspreyData<-IL_OspreyData[IL_OspreyData$ID %in% keep, ] 
```

Clean and filter the data further. 
```{r}
#Rename lat/lon columns cause the names currently will cause issues
names(IL_OspreyData) [names(IL_OspreyData) == "Longitude(E)"] <- "location_long"
names(IL_OspreyData) [names(IL_OspreyData) == "Latitude(N)"] <- "location_lat"
#Remove NAs from lat/lon
IL_OspreyData<-filter(IL_OspreyData, location_lat !=0 | location_long != 0)
#Create timestamp
IL_OspreyData$TimeStamp<-as.POSIXct(IL_OspreyData$TimeStamp, format = "%m/%d/%Y %H:%M", tz = "UTC")
#Calculate Solar Time
IL_OspreyData$timestamp<-local2Solar(IL_OspreyData$TimeStamp, IL_OspreyData$location_long)
IL_OspreyData$timestamp<-as.POSIXct(IL_OspreyData$TimeStamp, format = "%m/%d/%Y %H:%M")
#Filter data further
IL_OspreyData <- IL_OspreyData %>%
  filter(Month %in% c(6:12))
quantile(IL_OspreyData$Course, probs = 0.9) #got 252
IL_OspreyData<-filter(IL_OspreyData, Speed <= 33.4 & Course < 252)
#Plot and look for visual outliers
IL_OspreyData_sf<-st_as_sf(x=IL_OspreyData, coords = c("location_long", "location_lat"), crs = wgs84)
IL_OspreyData_sf<-st_transform(IL_OspreyData_sf, azim_orign)
ggplot() +
  geom_sf(data = world_sf, fill = "white") +
  geom_sf(data = IL_OspreyData_sf, size = 1, aes(color = ID)) +
  coord_sf(datum = st_crs(azim_orign), xlim = c(-3000000, 1000000), ylim = c(3000000, -2000000)) +
  theme(legend.position = "bottom", legend.text = element_text(size = 7)) +
  labs(color = "ID") #there is one erroneous point that must be removed at a high lat/long

#remove obvious visual outlier. The position of this outlier within the data table may change. To find it open the table view and filter to show only 69D. Then sort the latitude column by the largest value. 
IL_OspreyData<-IL_OspreyData[-4208, ]
IL_OspreyData_sf<-IL_OspreyData_sf[-4208, ]
ggplot() +
  geom_sf(data = world_sf, fill = "white") +
  geom_sf(data = IL_OspreyData_sf, size = 1, aes(color = ID)) +
  coord_sf(datum = st_crs(azim_orign), xlim = c(-3000000, 1000000), ylim = c(3000000, -2000000)) +
  theme(legend.position = "bottom", legend.text = element_text(size = 7)) +
  labs(color = "ID") 
```

## Combine Dataframes Into A Aingle Dataset And Create Migration Events IDs

Now it is time to combine all datasets into a single dataset to expedite the date filtering processes and migratory characteristics calculations. 
```{r}
#keep only columns needed for analysis: time stamp, individual ID, year, month, lat, lon, columns for each data set. Make sure the names of each column are the same between all data sets. Use the str() function to look at column names
IL_OspreyData<-IL_OspreyData[ ,c("ID", "Month", "Year", "timestamp", "location_lat", "location_long")] 
#rename to match movebank data
names(IL_OspreyData) [names(IL_OspreyData) == "Year"] <- "year"
names(IL_OspreyData) [names(IL_OspreyData) == "Month"] <- "month"
names(IL_OspreyData) [names(IL_OspreyData) == "ID"] <- "trackId"

Bierregaard_Osprey_Data2<-Bierregaard_Osprey_Data[ ,c("location_lat", "location_long", "timestamp", "trackId", "month", "year")]

Jensen_Osprey_Data2<-Jensen_Osprey_Data[ ,c("location_lat", "location_long", "timestamp", "trackId", "month", "year")]

#combine data sets
Osprey_Data<-rbind(Bierregaard_Osprey_Data2, Jensen_Osprey_Data2, IL_OspreyData)

# assign each migration event a unique ID that is the name of the name of the [animal Name]_[Migration Year]
Osprey_Data$migrationEvent<-paste(Osprey_Data$trackId, Osprey_Data$year)
length(unique(Osprey_Data$migrationEvent))

#Remove migration events where migration did not occur (or are from 2007)
remove<-c("Pearl 2013", "Rafael 2009","Luke 2007", "Aster 2017", "Chester 2014", "Felix 2007", "Claws 2007", "Claws 2008", "Mackenzie 2013", "Trepassey 2016", "Tucker 2011", "Jocelyn 2016", "Rammie 2013", "Snowy 2012", "Thatcher 2011", "Penelope 2009", "Buck 2010", "Belle 2011", "Flow 2015", "Art 2013", "Artoo 2014", "Crabby 2015", "Borealis 2018", "Daphne 2017", "Weber 2014", "Nick 2017", "Ron 2015", "Woody 2015", "Rodney 2014", "X586.Brighton_Barb 2015", "X934.Kensington.Pebbles 2017", "X423.Humphries_DTE_Ozzie 2015", "X139005.Monroe.Julie 2017")

# factor levels will be set to 0 in the data frame, but won't actually be removed. I have to change to character data format to remove rows.
Osprey_Data$migrationEvent<-as.character(Osprey_Data$migrationEvent)
Osprey_Data<-Osprey_Data[!(Osprey_Data$migrationEvent %in% remove), ]
length(unique(Osprey_Data$migrationEvent))
```

#### Filter Start And End Dates

Project the data and calculate NSD. To calculate NSD and run the dispersal model, the datset will need to be project and transformed into an ltraj object using the custom azimuthal projection and the package 'adehabitatLT'. 
```{r}
#Project data using custom azimuthal equidistant projection
Osprey_Data_sf<-st_as_sf(x=Osprey_Data, coords = c("location_long", "location_lat"), crs = wgs84)
Osprey_Data_sf<-st_transform(Osprey_Data_sf, azim_orign)

#Extract false easting and northing from our projected data which are in meters. 
False<-st_coordinates(Osprey_Data_sf) 
False<-as.data.frame(False)
Osprey_Data$X<-False$X/1000 #/1000 to equal kilometers. 
Osprey_Data$Y<-False$Y/1000
#Make a spatial data frame using the package 'sp'. 'adehabitatLR' requires an sp object rather than an sf object.  
Osprey_trajr<-Osprey_Data
coordinates(Osprey_trajr) <- c("X", "Y")
proj4string(Osprey_trajr) <- azim_orign

#Create an ltraj object using the 'adehabitat' package. ltraj objects automatically calculate NSD.
Osprey_trajr <- as.ltraj(coordinates(Osprey_trajr),
                          date=Osprey_trajr$timestamp,
                          id=Osprey_trajr$migrationEvent, typeII=TRUE)
```

Run the dispersal model to find start and end dates. I chose to use the dispersal model because I am analyzing only half of the ospreys' migration cycles. This means that the birds do not return to the area they started, which follows the definition of dispersal rather than migration or mixed migration within the dataset. If individuals appear with a warning "no dispersal model" then that individual either has to few points within its track or did not start migration. These migration events that have no associated model should be removed. Finally, tracks can be considered incomplete when the predicted end date of the model is after the last recorded GPS point an individual. 
```{r, warning=FALSE}
#Run the migrateR dispersal model
Osprey_nsd<-mvmtClass(Osprey_trajr)
Osprey_dispersal<-mvmt2dt(Osprey_nsd, mod = "disperser") #Note that some individuals did not fit dispersal patterns
length(Osprey_dispersal) #Some trajectories did not fit the dispersal model. These birds did not get far enough into migration for start and end dates to be determined. These 6 individuals will need to be removed: "Caleb 2013", "Layla 2017", "Rock 2017", "X131008.Lux.Arbor.In.Flight 2017", "X401.Houghton_Harvest 2014", "X610.Monroe_DTE_Clawdia 2015"

#extract the start and end dates for each migration event and create a dataframe for each migration event with start and end date as columns.
Osprey_StartEnd<-rbindlist(Osprey_dispersal, idcol = "migrationEvent")
Start_End<-rep(c("Start", "End"), times = nrow(Osprey_StartEnd)/2) #divide by two since this will be the number of EACH character that will appear. 
Osprey_StartEnd$Start_End<-Start_End
Osprey_StartEnd<-reshape(Osprey_StartEnd, idvar = "migrationEvent", 
                         timevar = "Start_End", direction = "wide")

#Remove individuals that did not have model fits:
remove2<-c("Caleb 2013", "Layla 2017", "Rock 2017", "X131008.Lux.Arbor.In.Flight 2017", "X401.Houghton_Harvist 2014", "X610.Monroe_DTE_Clawdia 2015")
Osprey_Data<-Osprey_Data[!(Osprey_Data$migrationEvent %in% remove2), ] #left with 142 migration events.

# compare the end timestamp to the final timestamp of each migration event. If the end date = final timestamp then the migration was not completed. Mark this in the excel file. 
Osprey_Data_FinalTrackDay<-Osprey_Data %>%
  group_by(migrationEvent) %>%
  slice_max(timestamp)
Osprey_Data_FinalTrackDay$FinalDay<-Osprey_Data_FinalTrackDay$timestamp

Osprey_StartEnd<-merge(Osprey_StartEnd, Osprey_Data_FinalTrackDay, by = "migrationEvent")
Osprey_StartEnd<-Osprey_StartEnd[, c("migrationEvent", "date.Start", "date.End", "FinalDay", "month", "year", "location_lat", "location_long")]
Osprey_StartEnd
```

One limitation/caveate that should be noted about the model is that the model cannot take into account the actual complexity of migration events. For example, 26R spent 1 month at a location outside of his natal home range before continuing on migration without going back to his home range. Leaving his natal home range could be considered the start of his migration, or the directional flight to his wintering grounds from this pre-migratory stopover could be considered the start of migration. The model provides the later interpretation. 

Filter GPS points by start/end dates and create 4 different datasets with different sampling frequencies. 
```{r}
#Keep only GPS fixes that fall within the start-end day range for each migration event. We could go to seconds/minutes ect., however we will use duration in days, so may as well keep all timestamps within the start/end day. 
events<-unique(Osprey_Data$migrationEvent)
df<-data.frame() #create an empty dataframe to store results

for (i in events) {
  y = filter(Osprey_Data, migrationEvent == i)
  x = filter(Osprey_StartEnd, migrationEvent == i)
  z = filter(y, timestamp <= as.Date(x$date.End) & timestamp >= as.Date(x$date.Start)) #We find the start/end day
  df = rbind(df, z) #binds all iteration outputs into a single dataframe
}

length(unique(df$migrationEvent)) #142 migration events and 115 individuals
```

## Thin The Trajectory

#### Transform the trajectory into a move stack object
This is not as straightforward as it sounds. Coercing a dataframe object to a move object requires very specific formatting. To help with this I use the 'moveVis' package to transform my data into a move stack object. 
```{r}
#Convert to a move object. To do this I had to use the moveVis package since the move function does not work well with actual dataframes. The move package has a number of very convinient functions that allow me to calculate a number of different movement characteristics and prep the data from analysis.
OSPR<-df2move(df,
        proj = wgs84, 
        x = "location_long", y = "location_lat", 
        time = "timestamp", track_id = "migrationEvent")

#regularize the time series through the move package. To do this we will have to apply the regularization to each move object within the movestack (annoying, I know). The interpolate time function fills in positional points along a standard time series. We will use 1-hour to do this. 
Stacked<-list() #empty list for output

for (i in 1:142) {
  x<-interpolateTime(OSPR[[i]], time=as.difftime(1, units="hours"), spaceMethod='rhumbline')
  print(plot(OSPR[[i]], col="red",pch=20, main="By time interval"))
  print(points(x))
  print(lines(OSPR[[i]], col="red"))
  print(legend("bottomleft", c("True locations", "Interpolated locations"), 
               col=c("red", "black"), pch=c(20,1))) #all points have a black outline which is annoying
  Stacked[[i]] = x
}

#convert output list of move objects into a move stack.
OSPR_1hour<-moveStack(Stacked) 
str(OSPR_1hour@trackId) #check that all migration events are accounted for
#check to make sure time between points is one hour and not finer.
list_1hour<-timeLag(OSPR_1hour, units = "hours")
sapply(list_1hour, median) 
```

#### Thin the trajectory to different sampling frequencies
```{r}
#3-hour sampling frequency
Stacked_3hr<-list()
  
for (i in 1:142) {
  x<-thinTrackTime(OSPR_1hour[[i]], interval = as.difftime(3, units="hours"),
                          tolerance = as.difftime(15, units="mins"), criteria = "closest")
  split<-move::split(x)
  Stacked_3hr[[i]] = split$selected
}

OSPR_3hour<-moveStack(Stacked_3hr) 
str(OSPR_3hour@trackId)

#1-day sampling frequency
Stacked_1day<-list()
  
for (i in 1:142) {
  x<-thinTrackTime(OSPR_1hour[[i]], interval = as.difftime(1, units="days"),
                          tolerance = as.difftime(15, units="mins"), criteria = "closest")
  split<-move::split(x)
  Stacked_1day[[i]] = split$selected
}

OSPR_1day<-moveStack(Stacked_1day) 
str(OSPR_1day@trackId)

#3-day sampling frequency
Stacked_3day<-list()
  
for (i in 1:142) {
  x<-thinTrackTime(OSPR_1hour[[i]], interval = as.difftime(3, units="days"),
                          tolerance = as.difftime(15, units="mins"), criteria = "closest")
  split<-move::split(x)
  Stacked_3day[[i]] = split$selected
}

OSPR_3day<-moveStack(Stacked_3day) 
str(OSPR_3day@trackId)

#plot one of the migration events for each time period
plot(OSPR_1hour[[1]])
plot(OSPR_3hour[[1]])
plot(OSPR_1day[[1]])
plot(OSPR_3day[[1]])
```


## Calculate Trajectory Characteristics
Now we have all four datasets. The final step before analysis is to calculate trajectory characteristics.

#### Calculate primary characteristics 
First lets calculate primary characteristics with the move package and some secondary characteristics. Keep in mind that distance measurements need to be calculated using the custom azimuthal projection while angle measurements need to be calculated using a mercator projection. 
```{r}
#Project data with custom azimuthal equidistant projection
OSPR_1hour_azim <- spTransform(OSPR_1hour, CRSobj=azim_orign)
OSPR_3hour_azim <- spTransform(OSPR_3hour, CRSobj=azim_orign)
OSPR_1day_azim <- spTransform(OSPR_1day, CRSobj=azim_orign)
OSPR_3day_azim <- spTransform(OSPR_3day, CRSobj=azim_orign)

#calculating distance between consecutive GPS points (meters)
OSPR_1hour_azim$distance<-unlist(lapply(distance(OSPR_1hour_azim), c, NA))
OSPR_3hour_azim$distance<-unlist(lapply(distance(OSPR_3hour_azim), c, NA))
OSPR_1day_azim$distance<-unlist(lapply(distance(OSPR_1day_azim), c, NA))
OSPR_3day_azim$distance<-unlist(lapply(distance(OSPR_3day_azim), c, NA))

#calculating speed/velocity between consecutive GPS points (m/s)
OSPR_1hour_azim$speed<-unlist(lapply(speed(OSPR_1hour_azim), c, NA))
OSPR_3hour_azim$speed<-unlist(lapply(speed(OSPR_3hour_azim), c, NA))
OSPR_1day_azim$speed<-unlist(lapply(speed(OSPR_1day_azim), c, NA))
OSPR_3day_azim$speed<-unlist(lapply(speed(OSPR_3day_azim), c, NA))

#Project data with custom conformal projection: the Mercator projection is a conformal cylindrical projection
mercator = CRS("+init=epsg:4326") #this projection covers the world so no need to custom define projection attributes
OSPR_1hour_mercator <- spTransform(OSPR_1hour, CRSobj=mercator)
OSPR_3hour_mercator <- spTransform(OSPR_3hour, CRSobj=mercator)
OSPR_1day_mercator <- spTransform(OSPR_1day, CRSobj=mercator)
OSPR_3day_mercator <- spTransform(OSPR_3day, CRSobj=mercator)

#calculating absolute angle
OSPR_1hour_mercator$abs_angle<-unlist(lapply(angle(OSPR_1hour_mercator), c, NA))
OSPR_3hour_mercator$abs_angle<-unlist(lapply(angle(OSPR_3hour_mercator), c, NA))
OSPR_1day_mercator$abs_angle<-unlist(lapply(angle(OSPR_1day_mercator), c, NA))
OSPR_3day_mercator$abs_angle<-unlist(lapply(angle(OSPR_3day_mercator), c, NA))

#calculate Turning Angle
OSPR_1hour_mercator$rel_angle<-unlist(lapply(turnAngleGc
                                             (OSPR_1hour_mercator), 
                                             function(x) c(NA, x, NA)))
OSPR_3hour_mercator$rel_angle<-unlist(lapply(turnAngleGc
                                             (OSPR_3hour_mercator), 
                                             function(x) c(NA, x, NA)))
OSPR_1day_mercator$rel_angle<-unlist(lapply(turnAngleGc
                                             (OSPR_1day_mercator), 
                                             function(x) c(NA, x, NA)))
OSPR_3day_mercator$rel_angle<-unlist(lapply(turnAngleGc
                                             (OSPR_3day_mercator), 
                                             function(x) c(NA, x, NA)))

#calculating time measurements
OSPR_1hour_azim$lag<-unlist(lapply(timeLag(OSPR_1hour_azim, 
                                           units = "hours"), c, NA))
OSPR_3hour_azim$lag<-unlist(lapply(timeLag(OSPR_3hour_azim, 
                                           units = "hours"), c, NA))
OSPR_1day_azim$lag<-unlist(lapply(timeLag(OSPR_1day_azim, 
                                           units = "hours"), c, NA))
OSPR_3day_azim$lag<-unlist(lapply(timeLag(OSPR_3day_azim, 
                                           units = "hours"), c, NA))
```

#### Calculate secondary characteristics

Next I will transform my move objects into data frames and extract the characteristics plus coordinate and migration Event information. I will append the angular info from the Mercator projected data frames to the azimuthal dataframes then calculate angular velocity. 
```{r}
#1-hour
OSPR_1hour_azim_DF<-as.data.frame(OSPR_1hour_azim)
OSPR_1hour_mercator_DF<-as.data.frame(OSPR_1hour_mercator)
OSPR_1hour_azim_DF$rel_angle<-OSPR_1hour_mercator_DF$rel_angle
OSPR_1hour_azim_DF$abs_angle<-OSPR_1hour_mercator_DF$abs_angle
OSPR_1hour_azim_DF$turn_speed<-
  OSPR_1hour_azim_DF$speed * cos(OSPR_1hour_azim_DF$rel_angle)

#3-hour
OSPR_3hour_azim_DF<-as.data.frame(OSPR_3hour_azim)
OSPR_3hour_mercator_DF<-as.data.frame(OSPR_3hour_mercator)
OSPR_3hour_azim_DF$rel_angle<-OSPR_3hour_mercator_DF$rel_angle
OSPR_3hour_azim_DF$abs_angle<-OSPR_3hour_mercator_DF$abs_angle
OSPR_3hour_azim_DF$turn_speed<-
  OSPR_3hour_azim_DF$speed * cos(OSPR_3hour_azim_DF$rel_angle)

#1-day
OSPR_1day_azim_DF<-as.data.frame(OSPR_1day_azim)
OSPR_1day_mercator_DF<-as.data.frame(OSPR_1day_mercator)
OSPR_1day_azim_DF$rel_angle<-OSPR_1day_mercator_DF$rel_angle
OSPR_1day_azim_DF$abs_angle<-OSPR_1day_mercator_DF$abs_angle
OSPR_1day_azim_DF$turn_speed<-
  OSPR_1day_azim_DF$speed * cos(OSPR_1day_azim_DF$rel_angle)

#3-day
OSPR_3day_azim_DF<-as.data.frame(OSPR_3day_azim)
OSPR_3day_mercator_DF<-as.data.frame(OSPR_3day_mercator)
OSPR_3day_azim_DF$rel_angle<-OSPR_3day_mercator_DF$rel_angle
OSPR_3day_azim_DF$abs_angle<-OSPR_3day_mercator_DF$abs_angle
OSPR_3day_azim_DF$turn_speed<-
  OSPR_3day_azim_DF$speed * cos(OSPR_3day_azim_DF$rel_angle)
```

Finally, I will transform my dataframe into an ltraj object with the azimuthal equidistant projection so I can calculate FPT and displacement.
```{r}
#I will start with displacement. This is a summary characteristic denoted by the maximum net squared displacement value. 

#1-hour diplacement
OSPR_1hour_traj<-OSPR_1hour_azim_DF
coordinates(OSPR_1hour_traj) <- c("coords.x1", "coords.x2")
proj4string(OSPR_1hour_traj) <- azim_orign
OSPR_1hour_traj <- as.ltraj(coordinates(OSPR_1hour_traj),
                          date=OSPR_1hour_traj$timestamps,
                          id=OSPR_1hour_traj$trackId, typeII=TRUE)
R2n<-data.frame()

for (i in 1:142) {
  x<-as.numeric(max(OSPR_1hour_traj[[i]]$R2n))
  x<-sqrt(x)/1000
  R2n<-rbind(R2n, x)
}

id<-as.data.frame(id(OSPR_1hour_traj))
R2n_1hour<-cbind(R2n, id)
names(R2n_1hour) [names(R2n_1hour) == "X5465.44415202201"] <- "Displacement"
names(R2n_1hour) [names(R2n_1hour) == "id(OSPR_1hour_traj)"] <- "trackId"

#3-hour displacement
OSPR_3hour_traj<-OSPR_3hour_azim_DF
coordinates(OSPR_3hour_traj) <- c("coords.x1", "coords.x2")
proj4string(OSPR_3hour_traj) <- azim_orign
OSPR_3hour_traj <- as.ltraj(coordinates(OSPR_3hour_traj),
                          date=OSPR_3hour_traj$timestamps,
                          id=OSPR_3hour_traj$trackId, typeII=TRUE)

R2n_2<-data.frame()

for (i in 1:142) {
  x<-as.numeric(max(OSPR_3hour_traj[[i]]$R2n))
  x<-sqrt(x)/1000
  R2n_2<-rbind(R2n_2, x)
}

id<-as.data.frame(id(OSPR_3hour_traj))
R2n_3hour<-cbind(R2n_2, id)
names(R2n_3hour) [names(R2n_3hour) == "X5465.91011841111"] <- "Displacement"
names(R2n_3hour) [names(R2n_3hour) == "id(OSPR_3hour_traj)"] <- "trackId"

#1-day displacement
OSPR_1day_traj<-OSPR_1day_azim_DF
coordinates(OSPR_1day_traj) <- c("coords.x1", "coords.x2")
proj4string(OSPR_1day_traj) <- azim_orign
OSPR_1day_traj <- as.ltraj(coordinates(OSPR_1day_traj),
                          date=OSPR_1day_traj$timestamps,
                          id=OSPR_1day_traj$trackId, typeII=TRUE)

R2n_3<-data.frame()

for (i in 1:142) {
  x<-as.numeric(max(OSPR_1day_traj[[i]]$R2n))
  x<-sqrt(x)/1000
  R2n_3<-rbind(R2n_3, x)
}

id<-as.data.frame(id(OSPR_1day_traj))
R2n_1day<-cbind(R2n_3, id)
names(R2n_1day) [names(R2n_1day) == "X5351.57347720469"] <- "Displacement"
names(R2n_1day) [names(R2n_1day) == "id(OSPR_1day_traj)"] <- "trackId"

#3-day displacement
OSPR_3day_traj<-OSPR_3day_azim_DF
coordinates(OSPR_3day_traj) <- c("coords.x1", "coords.x2")
proj4string(OSPR_3day_traj) <- azim_orign
OSPR_3day_traj <- as.ltraj(coordinates(OSPR_3day_traj),
                          date=OSPR_3day_traj$timestamps,
                          id=OSPR_3day_traj$trackId, typeII=TRUE)

R2n_4<-data.frame()

for (i in 1:142) {
  x<-as.numeric(max(OSPR_3day_traj[[i]]$R2n))
  x<-sqrt(x)/1000
  R2n_4<-rbind(R2n_4, x)
}

id<-as.data.frame(id(OSPR_3day_traj))
R2n_3day<-cbind(R2n_4, id)
names(R2n_3day) [names(R2n_3day) == "X4923.65649986988"] <- "Displacement"
names(R2n_3day) [names(R2n_3day) == "id(OSPR_3day_traj)"] <- "trackId"
```

```{r}
#1-hour fpt
fpt_max_1hour<-data.frame()
for (i in 1:142) {
  x<-fpt(OSPR_1hour_traj[i], radii=0:100, units="hours") #calculate fpt
  y<- varlogfpt(x, graph=TRUE) #variogram of fpt
  z<-as.numeric(y[1,])
  fpt<-max(z, na.rm = TRUE) #maximum of the variogram
  fpt_max_1hour<-rbind(fpt_max_1hour, fpt)
}
mean(fpt_max_1hour$X15.6091543043523) #average maximum of the variogram. We will use 11 kilometers (r11 column) for fpt measurements for the 1-hour intervals
#function for extracting time values for fpt
fpt_1hour<-data.frame()
for (i in 1:142) {
  x<-fpt(OSPR_1hour_traj[i], radii=0:100, units="hours")
  y<-mean(x[[1]]$r11, na.rm = T) #we want mean fpt for each bird
  fpt_1hour<-rbind(fpt_1hour, y)
}
names(fpt_1hour) [names(fpt_1hour) == "X2.22704668048032"] <- "fpt"
id<-as.data.frame(id(OSPR_1hour_traj))
fpt_1hour<-cbind(fpt_1hour, id)
names(fpt_1hour) [names(fpt_1hour) == "id(OSPR_1hour_traj)"] <- "trackId"

#3-hour fpt
fpt_max_3hour<-data.frame()
for (i in 1:142) {
  x<-fpt(OSPR_3hour_traj[i], radii=0:100, units="hours") #calculate fpt
  y<- varlogfpt(x, graph=FALSE) #variogram of fpt
  z<-as.numeric(y[1,])
  fpt<-max(z, na.rm = TRUE)
  fpt_max_3hour<-rbind(fpt_max_3hour, fpt)
}
mean(fpt_max_3hour$X13.3839971838427) #10 km
fpt_3hour<-data.frame()
for (i in 1:142) {
  x<-fpt(OSPR_3hour_traj[i], radii=0:100, units="hours")
  y<-mean(x[[1]]$r10, na.rm = T)
  fpt_3hour<-rbind(fpt_3hour, y)
}
names(fpt_3hour) [names(fpt_3hour) == "X1.89983417609419"] <- "fpt"
id<-as.data.frame(id(OSPR_3hour_traj))
fpt_3hour<-cbind(fpt_3hour, id)
names(fpt_3hour) [names(fpt_3hour) == "id(OSPR_3hour_traj)"] <- "trackId"

#1-day
fpt_max_1day<-data.frame()
for (i in 1:142) {
  x<-fpt(OSPR_1day_traj[i], radii=0:100, units="hours") #calculate fpt
  y<- varlogfpt(x, graph=FALSE) #variogram of fpt
  z<-as.numeric(y[1,])
  fpt<-max(z, na.rm = TRUE)
  fpt_max_1day<-rbind(fpt_max_1day, fpt)
}
fpt_max_1day<-fpt_max_1day[-59,] #got an infinite value so I removed it
mean(fpt_max_1day) #6 km
fpt_1day<-data.frame()
for (i in 1:142) {
  x<-fpt(OSPR_1day_traj[i], radii=0:100, units="hours")
  y<-mean(x[[1]]$r6, na.rm = T)
  fpt_1day<-rbind(fpt_1day, y)
}
names(fpt_1day) [names(fpt_1day) == "X0.127976506840921"] <- "fpt"
id<-as.data.frame(id(OSPR_1day_traj))
fpt_1day<-cbind(fpt_1day, id)
names(fpt_1day) [names(fpt_1day) == "id(OSPR_1day_traj)"] <- "trackId"

#3-day
fpt_max_3day<-data.frame()
for (i in 1:142) {
  x<-fpt(OSPR_3day_traj[i], radii=0:100, units="hours") #calculate fpt
  y<- varlogfpt(x, graph=FALSE) #variogram of fpt
  z<-as.numeric(y[1,])
  fpt<-max(z, na.rm = TRUE)
  fpt_max_3day<-rbind(fpt_max_3day, fpt)
}
fpt_max_3day<-filter(fpt_max_3day, X0.356963985615098 != "-Inf")
mean(fpt_max_3day$X0.356963985615098) #6 km
fpt_3day<-data.frame()
for (i in 1:142) {
  x<-fpt(OSPR_3day_traj[i], radii=0:100, units="hours")
  y<-mean(x[[1]]$r6, na.rm = T)
  fpt_3day<-rbind(fpt_3day, y)
}
id<-as.data.frame(id(OSPR_3day_traj))
fpt_3day<-cbind(fpt_3day, id)
names(fpt_3day) [names(fpt_3day) == "X0.00223418578042695"] <- "fpt"
names(fpt_3day) [names(fpt_3day) == "id(OSPR_3day_traj)"] <- "trackId"
```

#### Summarize data
Lastly, I will summarize my data so that there is one observation of each variable per individual. This is needed for the Hierarchical Clustering Analysis. I should have the following numeric variables for each time frame:
1. **Time of migration (days)**
2. **Sinuosity**
3. **Total Distance (in km)**
4. **Average speed of migration**
5. **Average turning angle speed during migration**
6. **Average absolute angle**
7. **mean FPT**
8. **Start Date**
```{r}
#Displacement and mean fpt are already summarized. We will need total distance, average turning speed, average speed, time in days

#1-hour summary
OSPR_1hour_summary<-OSPR_1hour_azim_DF %>% group_by(trackId) %>%
  summarise(FirstDate=first(timestamps),
    LastDate=last(timestamps),
    duration = format(round(as.integer(
      difftime(LastDate,FirstDate, units = "days")), 1), 0),
    total_dist=sum(distance, na.rm = T)/1000,
    migrate_speed=mean(speed, na.rm = T),
    mean_turn_speed = mean(turn_speed, na.rm = T),
    mean_absolute = mean(abs_angle, na.rm = T),
    .groups = 'drop')%>%
  as.data.frame()
OSPR_1hour_summary<-merge(OSPR_1hour_summary, R2n_1hour, by = "trackId")
OSPR_1hour_summary$sinuosity<-
  OSPR_1hour_summary$total_dist/OSPR_1hour_summary$Displacement
OSPR_1hour_summary<-merge(OSPR_1hour_summary, fpt_1hour, by = "trackId")

#3-hour summary
OSPR_3hour_summary<-OSPR_3hour_azim_DF %>% group_by(trackId) %>%
  summarise(FirstDate=first(timestamps),
    LastDate=last(timestamps),
    duration = format(round(as.integer(
      difftime(LastDate,FirstDate, units = "days")), 1), 0),
    total_dist=sum(distance, na.rm = T)/1000,
    migrate_speed=mean(speed, na.rm = T),
    mean_turn_speed = mean(turn_speed, na.rm = T),
    mean_absolute = mean(abs_angle, na.rm = T),
    .groups = 'drop')%>%
  as.data.frame()
OSPR_3hour_summary<-merge(OSPR_3hour_summary, R2n_3hour, by = "trackId")
OSPR_3hour_summary$sinuosity<-
  OSPR_3hour_summary$total_dist/OSPR_3hour_summary$Displacement
OSPR_3hour_summary<-merge(OSPR_3hour_summary, fpt_3hour, by = "trackId")

#1-day summary
OSPR_1day_summary<-OSPR_1day_azim_DF %>% group_by(trackId) %>%
  summarise(FirstDate=first(timestamps),
    LastDate=last(timestamps),
    duration = format(round(as.integer(
      difftime(LastDate,FirstDate, units = "days")), 1), 0),
    total_dist=sum(distance, na.rm = T)/1000,
    migrate_speed=mean(speed, na.rm = T),
    mean_turn_speed = mean(turn_speed, na.rm = T),
    mean_absolute = mean(abs_angle, na.rm = T),
    .groups = 'drop')%>%
  as.data.frame()
OSPR_1day_summary<-merge(OSPR_1day_summary, R2n_1day, by = "trackId")
OSPR_1day_summary$sinuosity<-
  OSPR_1day_summary$total_dist/OSPR_1day_summary$Displacement
OSPR_1day_summary<-merge(OSPR_1day_summary, fpt_1day, by = "trackId")

#3-day summary
OSPR_3day_summary<-OSPR_3day_azim_DF %>% group_by(trackId) %>%
  summarise(FirstDate=first(timestamps),
    LastDate=last(timestamps),
    duration = format(round(as.integer(
      difftime(LastDate,FirstDate, units = "days")), 1), 0),
    total_dist=sum(distance, na.rm = T)/1000,
    migrate_speed=mean(speed, na.rm = T),
    mean_turn_speed = mean(turn_speed, na.rm = T),
    mean_absolute = mean(abs_angle, na.rm = T),
    .groups = 'drop')%>%
  as.data.frame()
OSPR_3day_summary<-merge(OSPR_3day_summary, R2n_3day, by = "trackId")
OSPR_3day_summary$sinuosity<-
  OSPR_3day_summary$total_dist/OSPR_3day_summary$Displacement
OSPR_3day_summary<-merge(OSPR_3day_summary, fpt_3day, by = "trackId")
```

Then I will add independent variables using the individual metadata file I created. 
1. **Sex**
2. **Age**
3. **Migration Flyway**
4. **Latitudinal Origin** (latitude at the start of migration)
5. **Regional Origin** - Based on the study
7. **Year of migration**
8. **complete or incomplete**

```{r}
#get the starting latitude from the original dataset.
Latitude<-Osprey_Data %>%
  group_by(migrationEvent) %>%
  summarise(max(location_lat))
#Load in metadata. This is also part of the project file
IndividualMetadata <- read_csv("IndividualMetadata.csv")
#adjust the names so that I can merge this data with the metadata file. 
Latitude$migrationEvent<-gsub(" ", ".", Latitude$migrationEvent)
Latitude$migrationEvent[1:9]<-sub("^","X",Latitude$migrationEvent[1:9])
IndividualMetadata<-merge(Latitude, IndividualMetadata, by.x = "migrationEvent", by.y = "TrackId")

#merge dataframe, keep only the needed columns, rename the columns, and remove unknown sexes and ages
OSPR_1hour_summary<-merge(OSPR_1hour_summary, IndividualMetadata, by.x = "trackId", by.y = "migrationEvent")
OSPR_1hour_summary<-OSPR_1hour_summary[ ,c("trackId", "ID", "FirstDate", "Displacement", "duration", "total_dist", "migrate_speed", "mean_turn_speed", "mean_absolute", "sinuosity", "fpt", "Multiple", "Study", "Migration Year", "Flyway", "Status", "Year Born", "Sex", "Age", "max(location_lat)")] 
names(OSPR_1hour_summary) [names(OSPR_1hour_summary) == "ID"] <- "Individual"
names(OSPR_1hour_summary) [names(OSPR_1hour_summary) == "mean_turn_speed"] <- "turn_speed"
names(OSPR_1hour_summary) [names(OSPR_1hour_summary) == "mean_absolute"] <- "abs_angle"
names(OSPR_1hour_summary) [names(OSPR_1hour_summary) == "Study"] <- "Origin"
names(OSPR_1hour_summary) [names(OSPR_1hour_summary) == "Migration Year"] <- "Migration_Year"
names(OSPR_1hour_summary) [names(OSPR_1hour_summary) == "Year Born"] <- "Birth_Year"
names(OSPR_1hour_summary) [names(OSPR_1hour_summary) == "max(location_lat)"] <- "Start_Lat"
OSPR_1hour_summary$duration<-as.numeric(OSPR_1hour_summary$duration)
OSPR_1hour_summary<-filter(OSPR_1hour_summary, Sex != "Unkown") #124 migration events with 78 individuals
OSPR_1hour_summary<-filter(OSPR_1hour_summary, Age != "Unkown")
OSPR_1hour_summary<-filter(OSPR_1hour_summary, trackId != "Rodney.2014")

OSPR_3hour_summary<-merge(OSPR_3hour_summary, IndividualMetadata, by.x = "trackId", by.y = "migrationEvent")
OSPR_3hour_summary<-OSPR_3hour_summary[ ,c("trackId", "ID", "FirstDate", "Displacement", "duration", "total_dist", "migrate_speed", "mean_turn_speed", "mean_absolute", "sinuosity", "fpt", "Multiple", "Study", "Migration Year", "Flyway", "Status", "Year Born", "Sex", "Age", "max(location_lat)")] 
names(OSPR_3hour_summary) [names(OSPR_3hour_summary) == "ID"] <- "Individual"
names(OSPR_3hour_summary) [names(OSPR_3hour_summary) == "mean_turn_speed"] <- "turn_speed"
names(OSPR_3hour_summary) [names(OSPR_3hour_summary) == "mean_absolute"] <- "abs_angle"
names(OSPR_3hour_summary) [names(OSPR_3hour_summary) == "Study"] <- "Origin"
names(OSPR_3hour_summary) [names(OSPR_3hour_summary) == "Migration Year"] <- "Migration_Year"
names(OSPR_3hour_summary) [names(OSPR_3hour_summary) == "Year Born"] <- "Birth_Year"
names(OSPR_3hour_summary) [names(OSPR_3hour_summary) == "max(location_lat)"] <- "Start_Lat"
OSPR_3hour_summary$duration<-as.numeric(OSPR_3hour_summary$duration)
OSPR_3hour_summary<-filter(OSPR_3hour_summary, Sex != "Unkown")
OSPR_3hour_summary<-filter(OSPR_3hour_summary, Age != "Unkown")
OSPR_3hour_summary<-filter(OSPR_1hour_summary, trackId != "Rodney.2014")

OSPR_1day_summary<-merge(OSPR_1day_summary, IndividualMetadata, by.x = "trackId", by.y = "migrationEvent")
OSPR_1day_summary<-OSPR_1day_summary[ ,c("trackId", "ID", "FirstDate", "Displacement", "duration", "total_dist", "migrate_speed", "mean_turn_speed", "mean_absolute", "sinuosity", "fpt", "Multiple", "Study", "Migration Year", "Flyway", "Status", "Year Born", "Sex", "Age", "max(location_lat)")] 
names(OSPR_1day_summary) [names(OSPR_1day_summary) == "ID"] <- "Individual"
names(OSPR_1day_summary) [names(OSPR_1day_summary) == "mean_turn_speed"] <- "turn_speed"
names(OSPR_1day_summary) [names(OSPR_1day_summary) == "mean_absolute"] <- "abs_angle"
names(OSPR_1day_summary) [names(OSPR_1day_summary) == "Study"] <- "Origin"
names(OSPR_1day_summary) [names(OSPR_1day_summary) == "Migration Year"] <- "Migration_Year"
names(OSPR_1day_summary) [names(OSPR_1day_summary) == "Year Born"] <- "Birth_Year"
names(OSPR_1day_summary) [names(OSPR_1day_summary) == "max(location_lat)"] <- "Start_Lat"
OSPR_1day_summary$duration<-as.numeric(OSPR_1day_summary$duration)
OSPR_1day_summary<-filter(OSPR_1day_summary, Sex != "Unkown")
OSPR_1day_summary<-filter(OSPR_1day_summary, Age != "Unkown")
OSPR_1day_summary<-filter(OSPR_1day_summary, trackId != "Rodney.2014")

OSPR_3day_summary<-merge(OSPR_3day_summary, IndividualMetadata, by.x = "trackId", by.y = "migrationEvent")
OSPR_3day_summary<-OSPR_3day_summary[ ,c("trackId", "ID", "FirstDate", "Displacement", "duration", "total_dist", "migrate_speed", "mean_turn_speed", "mean_absolute", "sinuosity", "fpt", "Multiple", "Study", "Migration Year", "Flyway", "Status", "Year Born", "Sex", "Age", "max(location_lat)")] 
names(OSPR_3day_summary) [names(OSPR_3day_summary) == "ID"] <- "Individual"
names(OSPR_3day_summary) [names(OSPR_3day_summary) == "mean_turn_speed"] <- "turn_speed"
names(OSPR_3day_summary) [names(OSPR_3day_summary) == "mean_absolute"] <- "abs_angle"
names(OSPR_3day_summary) [names(OSPR_3day_summary) == "Study"] <- "Origin"
names(OSPR_3day_summary) [names(OSPR_3day_summary) == "Migration Year"] <- "Migration_Year"
names(OSPR_3day_summary) [names(OSPR_3day_summary) == "Year Born"] <- "Birth_Year"
names(OSPR_3day_summary) [names(OSPR_3day_summary) == "max(location_lat)"] <- "Start_Lat"
OSPR_3day_summary$duration<-as.numeric(OSPR_3day_summary$duration)
OSPR_3day_summary<-filter(OSPR_3day_summary, Sex != "Unkown")
OSPR_3day_summary<-filter(OSPR_3day_summary, Age != "Unkown")
OSPR_3day_summary<-filter(OSPR_3day_summary, trackId != "Rodney.2014")
```

## Data Analysis

#### Exploratory data analysis

First I will look at the distribution of data for each sampling frequency using histograms, correlation, and PCA. The distribution of my data will determine the kinds of tests I employ later on. 
```{r}
#normality and correlation of dependent variables using 'PerformanceAnalytics' package
chart.Correlation(OSPR_1hour_summary[, 4:10], histogram=TRUE, pch=19, method = "spearman")
chart.Correlation(OSPR_3hour_summary[, 4:10], histogram=TRUE, pch=19, method = "spearman")
chart.Correlation(OSPR_1day_summary[, 4:10], histogram=TRUE, pch=19, method = "spearman")
chart.Correlation(OSPR_3day_summary[, 4:10], histogram=TRUE, pch=19, method = "spearman")

#positive high correlation between sinuosity and duration (maintained); distance and duration correlated (but strength of correlation decreases with increasing sampling frequency); speed and duration negatively correlated with higher degree of correlation as sampling frequency decreases


#Next I will run a PCA and visualize my different groupings:
OSPR_1hour_PCA<-PCA(OSPR_1hour_summary[, 4:10], scale.unit = T, graph = F) #PCA function automatically normalizes my data with scale.unit = T
OSPR_3hour_PCA<-PCA(OSPR_3hour_summary[, 4:10], scale.unit = T, graph = F)
OSPR_1day_PCA<-PCA(OSPR_1day_summary[, 4:10], scale.unit = T, graph = F)
OSPR_3day_PCA<-PCA(OSPR_3day_summary[, 4:10], scale.unit = T, graph = F)

#I will make a biplot, but the biplot only shows the first two PCs. A scree-plot will show me how much of the variance of my data is represented
fviz_eig(OSPR_1hour_PCA, addlabels = T) #57.3% in first two, 73.9% in first three
fviz_eig(OSPR_3hour_PCA, addlabels = T) #55.5% in first two, 71.9% in first three
fviz_eig(OSPR_1day_PCA, addlabels = T) #53.4% in first two, 69.8%
fviz_eig(OSPR_3day_PCA, addlabels = T) #56% in first two, 70.8%
# the variance represented by the first two and three components is not that different between datasets

#Lets look at a PCA bi-plot to see how variables relate
plot(OSPR_1hour_PCA, choix = "var", title = "1-hour PCA")
plot(OSPR_3hour_PCA, choix = "var", title = "1-hour PCA") #How the variables make up the PCs does not change between the 1 and 3 hour sampling frequencies. Some change in the magnitude of contribution for some variables, but not a lot. 
plot(OSPR_1day_PCA, choix = "var", title = "1-hour PCA") #turning speed becomes negligible. 
plot(OSPR_3day_PCA, choix = "var", title = "1-hour PCA")
#The contribution of migration speed, total distance, and absolute angle to the first two PCs are the most constant characteristic for all plots. 


#Now lets look at relationship at the variance and overlap between sex, age, flyway, and origin. I'll need to turn these variables into factors to use them in the plot
OSPR_1hour_summary$Sex<-as.factor(OSPR_1hour_summary$Sex)
OSPR_3hour_summary$Sex<-as.factor(OSPR_3hour_summary$Sex)
OSPR_1day_summary$Sex<-as.factor(OSPR_1day_summary$Sex)
OSPR_3day_summary$Sex<-as.factor(OSPR_3day_summary$Sex)
OSPR_1hour_summary$Age<-as.factor(OSPR_1hour_summary$Age)
OSPR_3hour_summary$Age<-as.factor(OSPR_3hour_summary$Age)
OSPR_1day_summary$Age<-as.factor(OSPR_1day_summary$Age)
OSPR_3day_summary$Age<-as.factor(OSPR_3day_summary$Age)
OSPR_1hour_summary$Flyway<-as.factor(OSPR_1hour_summary$Flyway)
OSPR_3hour_summary$Flyway<-as.factor(OSPR_3hour_summary$Flyway)
OSPR_1day_summary$Flyway<-as.factor(OSPR_1day_summary$Flyway)
OSPR_3day_summary$Flyway<-as.factor(OSPR_3day_summary$Flyway)
OSPR_1hour_summary$Origin<-as.factor(OSPR_1hour_summary$Origin)
OSPR_3hour_summary$Origin<-as.factor(OSPR_3hour_summary$Origin)
OSPR_1day_summary$Origin<-as.factor(OSPR_1day_summary$Origin)
OSPR_3day_summary$Origin<-as.factor(OSPR_3day_summary$Origin)

# PCA biplots

fviz_pca_ind(OSPR_1hour_PCA, 
             geom = "point", 
             label = "none", 
             habillage = OSPR_1hour_summary$Origin, 
             addEllipses=TRUE, ellipse.level=0.95)
fviz_pca_ind(OSPR_3hour_PCA, 
             geom = "point", 
             label = "none", 
             habillage = OSPR_3hour_summary$Origin, 
             addEllipses=TRUE, ellipse.level=0.95)
fviz_pca_ind(OSPR_1day_PCA, 
             geom = "point", 
             label = "none", 
             habillage = OSPR_1day_summary$Origin, 
             addEllipses=TRUE, ellipse.level=0.95)
fviz_pca_ind(OSPR_3day_PCA, 
             geom = "point", 
             label = "none", 
             habillage = OSPR_3day_summary$Origin, 
             addEllipses=TRUE, ellipse.level=0.95)

#Does not seem there are difference between sexes or between time period for sexes
#Some difference between adults and juveniles seem to exist in that juveniles have more variable migration strategies (more variance within the data) than adults. Dispersion differences become less apparent as the sampling frequency becomes courser
#Some difference in migration strategies seem to exist between route choices. Coast of Mexico different than the other two routes, although there really isn't sufficient data to make conclusions. CAR route is fairly  constant between sampling frequency, probably because it has the most data. 
#No differences between origins
```

#### Testing hypotheses in osprey literature

Are osprey leap-frog migrants -> Do osprey starting at higher latitudes migrate further?

```{r}
# 1-hour
# Are osprey leap-frog migrants: do birds that migrate further, start further north?
plot(OSPR_1hour_summary$Displacement, OSPR_1hour_summary$Start_Lat)
summary(lm(Displacement ~ Start_Lat, data = OSPR_1hour_summary)) # Apparently not...
plot(OSPR_3hour_summary$Displacement, OSPR_3hour_summary$Start_Lat)
summary(lm(Displacement ~ Start_Lat, data = OSPR_3hour_summary)) #nope
plot(OSPR_1day_summary$Displacement, OSPR_1day_summary$Start_Lat)
summary(lm(Displacement ~ Start_Lat, data = OSPR_1day_summary)) #nope
plot(OSPR_3day_summary$Displacement, OSPR_3day_summary$Start_Lat)
summary(lm(Displacement ~ Start_Lat, data = OSPR_3day_summary)) #nope
#osprey are not leap-frog migrants (I also ran it with total distance and got the same results)
```

Do osprey exhibit differential migration between sexes where one sex migrates further than another? At the moment I can't test whether this is impact by region of origin.
```{r}
#1-hour
#Female osprey are known to migrate further than males: Is this true and does it influence the trends above?
OSPR_1hour_summary_complete<-filter(OSPR_1hour_summary, Status !="Incomplete")
ggplot(OSPR_1hour_summary_complete, aes(x=Start_Lat, y = Displacement, col = Sex)) +
  geom_point()
boxplot(Displacement~Sex, data = OSPR_1hour_summary_complete)
#check to make sure variances are homogeneous (assumption of the unpaired two way t-test).
M_1hour<-subset(OSPR_1hour_summary_complete, Sex == "M")
F_1hour<-subset(OSPR_1hour_summary_complete, Sex == "F")
chart.Correlation(M_1hour[, 4:10], histogram=TRUE, pch=19, method = "spearman")
chart.Correlation(F_1hour[, 4:10], histogram=TRUE, pch=19, method = "spearman")
var.test(M_1hour$Displacement, F_1hour$Displacement) #p-value>0.05 by a lot. no siginficant differences between the variances. The distance data seems to be normally distributed from the corr plots above = we can run the t-test
t.test(M_1hour$Displacement, F_1hour$Displacement, var.equal=TRUE) #significant p = 0.0044.Total distance traveled by males is different from females. 
#females travel further than males by an average of about 800 kilometers. 

# 3-hours
OSPR_3hour_summary_complete<-filter(OSPR_3hour_summary, Status !="Incomplete")
ggplot(OSPR_3hour_summary_complete, aes(x=Start_Lat, y = Displacement, col = Sex)) +
  geom_point()
boxplot(Displacement~Sex, data = OSPR_3hour_summary_complete)
#check to make sure variances are homogeneous (assumption of the unpaired two way t-test).
M_3hour<-subset(OSPR_3hour_summary_complete, Sex == "M")
F_3hour<-subset(OSPR_3hour_summary_complete, Sex == "F")
chart.Correlation(M_3hour[, 4:10], histogram=TRUE, pch=19, method = "spearman")
chart.Correlation(F_3hour[, 4:10], histogram=TRUE, pch=19, method = "spearman")
var.test(M_3hour$Displacement, F_3hour$Displacement) #p-value>0.05 by a lot. no siginficant differences between the variances. The distance data seems to be normally distributed from the corr plots above = we can run the t-test
t.test(M_3hour$Displacement, F_3hour$Displacement, var.equal=TRUE) #significant p = 0.0046.Total distance traveled by males is different from females. 
#females travel further than males.

# 1-day
OSPR_1day_summary_complete<-filter(OSPR_1day_summary, Status !="Incomplete")
ggplot(OSPR_1day_summary_complete, aes(x=Start_Lat, y = Displacement, col = Sex)) +
  geom_point()
boxplot(Displacement~Sex, data = OSPR_1day_summary_complete)
#check to make sure variances are homogeneous (assumption of the unpaired two way t-test).
M_1day<-subset(OSPR_1day_summary_complete, Sex == "M")
F_1day<-subset(OSPR_1day_summary_complete, Sex == "F")
chart.Correlation(M_1day[, 4:10], histogram=TRUE, pch=19, method = "spearman")
chart.Correlation(F_1day[, 4:10], histogram=TRUE, pch=19, method = "spearman")
var.test(M_1day$Displacement, F_1day$Displacement) #p-value>0.05 by a lot. no siginficant differences between the variances. The distance data seems to be normally distributed, but less so than from the other two sampling periods from the corr plots above = we can run the t-test
t.test(M_1day$Displacement, F_1day$Displacement, var.equal=TRUE) #significant p = 0.0053.Total distance traveled by males is different from females. 
#females travel further than males by an average of about 900 kilometers, although the actual distance traveled continues to decrease as the sampling frequency becomes courser

# 3-day
OSPR_3day_summary_complete<-filter(OSPR_3day_summary, Status !="Incomplete")
ggplot(OSPR_3day_summary_complete, aes(x=Start_Lat, y = Displacement, col = Sex)) +
  geom_point()
boxplot(Displacement~Sex, data = OSPR_3day_summary_complete)
#check to make sure variances are homogeneous (assumption of the unpaired two way t-test).
M_3day<-subset(OSPR_3day_summary_complete, Sex == "M")
F_3day<-subset(OSPR_3day_summary_complete, Sex == "F")
chart.Correlation(M_3day[, 4:10], histogram=TRUE, pch=19, method = "spearman")
chart.Correlation(F_3day[, 4:10], histogram=TRUE, pch=19, method = "spearman")
var.test(M_3day$Displacement, F_3day$Displacement) #p-value>0.05 by a lot, however the heteroscedasticity is becoming more apparent = the variances between the two data sets are becoming more different, yet there are still no significant differences between the variances. The distance data seems to be normally distributed, but less so than from the other two sampling periods from the corr plots above = we can run the t-test
t.test(M_3day$Displacement, F_3day$Displacement, var.equal=TRUE) #significant p = 0.0061.Total distance traveled by males is different from females. 


#conclusions: Females travel further on average than males when they start at latitudes below 40 or above 45. Females seem to travel similar distances to males when they start mid-latitude
```

Do osprey exhibit differential migration between age groups where one age group migrates further than another or has a more sinuous flight path?
```{r}
#1-hour
ggplot(OSPR_1hour_summary_complete, aes(x=Start_Lat, y = Displacement, col = Age)) +
  geom_point()
boxplot(Displacement~Age, data = OSPR_1hour_summary_complete)
J_1hour<-subset(OSPR_3hour_summary_complete, Age == "Juvenile")
A_1hour<-subset(OSPR_3hour_summary_complete, Age == "Adult")
chart.Correlation(J_1hour[, 4:10], histogram=TRUE, pch=19, method = "spearman")
chart.Correlation(A_1hour[, 4:10], histogram=TRUE, pch=19, method = "spearman")
var.test(J_1hour$Displacement, A_1hour$Displacement) #no difference
t.test(J_1hour$Displacement, A_1hour$Displacement, var.equal=TRUE) #There is a significant difference, p = 0.009 (birds at higher latitudes where juveniles will fly less distance than adults)

#3-hour
ggplot(OSPR_3hour_summary_complete, aes(x=Start_Lat, y = Displacement, col = Age)) +
  geom_point()
boxplot(Displacement~Age, data = OSPR_3hour_summary_complete)
J_3hour<-subset(OSPR_3hour_summary_complete, Age == "Juvenile")
A_3hour<-subset(OSPR_3hour_summary_complete, Age == "Adult")
chart.Correlation(J_3hour[, 4:10], histogram=TRUE, pch=19, method = "spearman")
chart.Correlation(A_3hour[, 4:10], histogram=TRUE, pch=19, method = "spearman")
var.test(J_3hour$Displacement, A_3hour$Displacement) #no difference
t.test(J_3hour$Displacement, A_3hour$Displacement, var.equal=TRUE) #There is a significant difference (birds at higher latitudes where juveniles will fly less distance than adults)

#1-day
ggplot(OSPR_1day_summary_complete, aes(x=Start_Lat, y = Displacement, col = Age)) +
  geom_point()
boxplot(Displacement~Age, data = OSPR_1day_summary_complete)
J_1day<-subset(OSPR_1day_summary_complete, Age == "Juvenile")
A_1day<-subset(OSPR_1day_summary_complete, Age == "Adult")
chart.Correlation(J_1day[, 4:10], histogram=TRUE, pch=19, method = "spearman")
chart.Correlation(A_1day[, 4:10], histogram=TRUE, pch=19, method = "spearman")
var.test(J_1day$Displacement, A_1day$Displacement) #no difference
t.test(J_1day$Displacement, A_1day$Displacement, var.equal=TRUE) #There is a significant difference p = 0.02 (birds at higher latitudes where juveniles will fly less distance than adults)

#3-day
ggplot(OSPR_3day_summary_complete, aes(x=Start_Lat, y = Displacement, col = Age)) +
  geom_point()
boxplot(Displacement~Age, data = OSPR_3day_summary_complete)
J_3day<-subset(OSPR_3day_summary_complete, Age == "Juvenile")
A_3day<-subset(OSPR_3day_summary_complete, Age == "Adult")
chart.Correlation(J_3day[, 4:10], histogram=TRUE, pch=19, method = "spearman")
chart.Correlation(A_3day[, 4:10], histogram=TRUE, pch=19, method = "spearman")
var.test(J_3day$Displacement, A_3day$Displacement) #no difference
t.test(J_3day$Displacement, A_3day$Displacement, var.equal=TRUE) #significant difference p = 0.021.

#Conclusion: I saw a significant difference between the total distance traveled by juveniles compared to adults. Juveniles supposedly traveled less distance than adults, however I do not think these results reflect the biology of osprey. All male osprey starting at higher latitudes (where differentiation between sexes occurs) were juvenile while all females were adults. This means that my data actually reflects sexual differentiation rather than age. When looking at lower and mid latitudes, juveniles were evenly mixed with adults. Finally, my p-values for distance ~ age were similar suggesting that sex may have skewed my results.
#The actual influence of sex, age, and latitude on distance is still unknown without a larger sample size of both adult and juvenile females from various latitudes. 

#Conclusions: Similar conclusions with displacement except that the p-values for differences between sex were smaller while the p-values between age were larger suggesting that sex may be more influencial...
```

Create a table for these results...

I predict migration strategies should be impacted by the distance the bird flies, the sex, and the age of the bird. However, I do not have enough data on origin of the birds to make any conclusions and the sexes and age data is very skewed. Instead of attempting to determine the relationship between groups, I can use HCA to determine the relationship between individuals and use a heat map + annotations to compare the differences in demographics, geographic origin, and migratory characteristics to get a better idea of how osprey with more similar strategies relate to one another. I can also look for distinct clusters within my data and use a PERMANOVA to test if clusters are significantly different. 

#### HCA
```{r}
# 1-hour
#normalize data for HCA using z scores since our data is skewed
OSPR_1hour_norm<-lapply(OSPR_1hour_summary[,5:11], scale)
OSPR_1hour_norm<-cbind(OSPR_1hour_norm, OSPR_1hour_summary[,c(1:4, 12:20)])
#determine the best linake method
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")
ac <- function(x) {
  agnes(OSPR_1hour_norm[,1:7], method = x)$ac
}
sapply(m, ac) #ward is best for identifying strongest clustering structure

#optimal clusters
NbClust(OSPR_1hour_norm[,1:7], method = "ward.D2", index = "all")$Best.nc # 2 clusters

#Create dendrogram and clusters
OSPR_1hour_clust <- OSPR_1hour_norm[,1:7] %>% dist %>% hclust(method = "ward.D2") %>% as.dendrogram
labels(OSPR_1hour_clust) <- paste(as.character(OSPR_1hour_norm[,8])[order.dendrogram(OSPR_1hour_clust)])
SexColors<-c(M = "Blue", F = "Red")
labels_colors(OSPR_1hour_clust) <-
   SexColors[sort_levels_values(
      as.numeric(OSPR_1hour_norm[,18])[order.dendrogram(OSPR_1hour_clust)]
   )]
OSPR_1hour_clust<-color_branches(OSPR_1hour_clust, k = 2, col = c("#FF0000", "#E462C7"))
OSPR_1hour_clust %>%
  set("labels_cex", 0.3) %>%        # change label size
  plot()

#Create a heatmap
OSPR_1hour_clust <- OSPR_1hour_norm[,1:7] %>% dist %>% hclust(method = "ward.D2") %>% as.dendrogram %>% ladderize
labels(OSPR_1hour_clust) <- paste(as.character(OSPR_1hour_norm[,8])
                                  [order.dendrogram(OSPR_1hour_clust)])
OSPR_1hour_clust<-color_branches(OSPR_1hour_clust, k = 2, col = c("#FF0000", "#E462C7"))

#make a color palette
col1<-colorRampPalette(colors = c("#593CD8", "#AA4499"), space = "Lab")(20)
col2<-colorRampPalette(colors = c("#CC6677", "#EFD347"), space = "Lab")(40)
rampcols <- c(col1, col2)

#Reorder the data set for labeling
target<-as.data.frame(labels(OSPR_1hour_clust))
OSPR_1hour_norm<-OSPR_1hour_norm[ order(match(OSPR_1hour_norm$trackId, 
                             target$`labels(OSPR_1hour_clust)`)), ]
row_dend = dendsort(OSPR_1hour_clust)
annotation<-rowAnnotation(df = OSPR_1hour_norm[,c("Start_Lat", "Age", "Sex", "Birth_Year", "Status", "Origin", "Multiple")])
#row_labels = OSPR_1hour_norm$trackId,
Heatmap(as.matrix(OSPR_1hour_norm[,1:7]),
        col = rampcols,
        cluster_columns = F,
        name = "Scaled",
        column_title = "Migration Characteristics",
        column_title_side = "bottom",
        column_labels = c("Duration", "Total Distance", "Migration Speed", 
                          "Turn Speed","Turn Angle", "Sinuosity", 
                          "First Passage Time"),
        column_names_gp = gpar(fontsize = 8),
        column_names_rot = 45,
        cluster_rows = row_dend,
        row_title = "Migration Events",
        show_row_names = F,
        row_names_gp = gpar(fontsize = 2),
        row_dend_width = unit(3, "cm"),
        row_split = 2,
        border = TRUE,
        left_annotation = annotation
        )

```
Why is my dendrogram not sorting correctly????

```{r}
# 3-hour
OSPR_3hour_norm<-lapply(OSPR_3hour_summary[,5:11], scale)
OSPR_3hour_norm<-cbind(OSPR_3hour_norm, OSPR_3hour_summary[,c(1:4, 12:19)])
#determine the best linake method
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")
ac <- function(x) {
  agnes(OSPR_3hour_norm[,1:7], method = x)$ac
}
sapply(m, ac) #ward is best for identifying strongest clustering structure
NbClust(OSPR_3hour_norm[,1:7], method = "ward.D2", index = "all")$Best.nc # 2 clusters

#Create dendrogram and clusters
OSPR_3hour_clust <- OSPR_3hour_norm[,1:7] %>% dist %>% hclust(method = "ward.D2") %>% as.dendrogram
labels(OSPR_3hour_clust) <- paste(as.character(OSPR_3hour_norm[,8])[order.dendrogram(OSPR_3hour_clust)])
SexColors<-c(M = "Blue", F = "Red")
labels_colors(OSPR_3hour_clust) <-
   SexColors[sort_levels_values(
      as.numeric(OSPR_3hour_norm[,18])[order.dendrogram(OSPR_3hour_clust)]
   )]
OSPR_3hour_clust<-color_branches(OSPR_3hour_clust, k = 2, col = c("#FF0000", "#E462C7"))
OSPR_3hour_clust %>%
  set("labels_cex", 0.3) %>%        # change label size
  plot()

#Create a heatmap
OSPR_3hour_clust <- OSPR_3hour_norm[,1:7] %>% dist %>% hclust(method = "ward.D2") %>% as.dendrogram %>% ladderize
labels(OSPR_3hour_clust) <- paste(as.character(OSPR_3hour_norm[,8])
                                  [order.dendrogram(OSPR_3hour_clust)])
OSPR_3hour_clust<-color_branches(OSPR_3hour_clust, k = 2, col = c("#FF0000", "#E462C7"))

#Reorder the data set for labeling
target<-as.data.frame(labels(OSPR_3hour_clust))
OSPR_3hour_norm<-OSPR_3hour_norm[ order(match(OSPR_3hour_norm$trackId, 
                             target$`labels(OSPR_3hour_clust)`)), ]
row_dend = dendsort(OSPR_3hour_clust)
annotation<-rowAnnotation(df = OSPR_3hour_norm[,13:19])

Heatmap(as.matrix(OSPR_3hour_norm[,1:7]),
        col = rampcols,
        cluster_columns = F,
        name = "Scaled",
        column_title = "Migration Characteristics",
        column_title_side = "bottom",
        column_labels = c("Duration", "Total Distance", "Migration Speed", 
                          "Turn Speed","Turn Angle", "Sinuosity", 
                          "First Passage Time"),
        column_names_gp = gpar(fontsize = 8),
        column_names_rot = 90,
        cluster_rows = row_dend,
        row_labels = OSPR_3hour_norm$trackId,
        row_title = "Migration Events",
        row_names_gp = gpar(fontsize = 2),
        row_dend_width = unit(3, "cm"),
        row_split = 3,
        border = TRUE
        )

```

```{r}
# 3-hour
OSPR_1day_norm<-lapply(OSPR_1day_summary[,5:11], scale)
OSPR_1day_norm<-cbind(OSPR_1day_norm, OSPR_1day_summary[,c(1:4, 12:19)])
#determine the best linake method
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")
ac <- function(x) {
  agnes(OSPR_1day_norm[,1:7], method = x)$ac
}
sapply(m, ac) #ward is best for identifying strongest clustering structure
NbClust(OSPR_1day_norm[,1:7], method = "ward.D2", index = "all")$Best.nc # 2 clusters

#Create dendrogram and clusters
OSPR_1day_clust <- OSPR_1day_norm[,1:7] %>% dist %>% hclust(method = "ward.D2") %>% as.dendrogram
labels(OSPR_1day_clust) <- paste(as.character(OSPR_1day_norm[,8])[order.dendrogram(OSPR_1day_clust)])
SexColors<-c(M = "Blue", F = "Red")
labels_colors(OSPR_1day_clust) <-
   SexColors[sort_levels_values(
      as.numeric(OSPR_1day_norm[,18])[order.dendrogram(OSPR_1day_clust)]
   )]
OSPR_1day_clust<-color_branches(OSPR_1day_clust, k = 2, col = c("#FF0000", "#E462C7"))
OSPR_1day_clust %>%
  set("labels_cex", 0.3) %>%      
  plot()

#Create a heatmap
OSPR_1day_clust <- OSPR_1day_norm[,1:7] %>% dist %>% hclust(method = "ward.D2") %>% as.dendrogram %>% ladderize
labels(OSPR_1day_clust) <- paste(as.character(OSPR_1day_norm[,8])
                                  [order.dendrogram(OSPR_1day_clust)])
OSPR_1day_clust<-color_branches(OSPR_1day_clust, k = 2, col = c("#FF0000", "#E462C7"))

#Reorder the data set for labeling
target<-as.data.frame(labels(OSPR_1day_clust))
OSPR_1day_norm<-OSPR_1day_norm[ order(match(OSPR_1day_norm$trackId, 
                             target$`labels(OSPR_1day_clust)`)), ]
row_dend = dendsort(OSPR_1day_clust)
annotation<-rowAnnotation(df = OSPR_1day_norm[,13:19])

Heatmap(as.matrix(OSPR_1day_norm[,1:7]),
        col = rampcols,
        cluster_columns = F,
        name = "Scaled",
        column_title = "Migration Characteristics",
        column_title_side = "bottom",
        column_labels = c("Duration", "Total Distance", "Migration Speed", 
                          "Turn Speed","Turn Angle", "Sinuosity", 
                          "First Passage Time"),
        column_names_gp = gpar(fontsize = 8),
        column_names_rot = 90,
        cluster_rows = row_dend,
        row_labels = OSPR_1day_norm$trackId,
        row_title = "Migration Events",
        row_names_gp = gpar(fontsize = 2),
        row_dend_width = unit(3, "cm"),
        row_split = 3,
        border = TRUE
        )

```

```{r}
# 3-hour
OSPR_3day_norm<-lapply(OSPR_3day_summary[,5:11], scale)
OSPR_3day_norm<-cbind(OSPR_3day_norm, OSPR_3day_summary[,c(1:4, 12:19)])
#determine the best linake method
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")
ac <- function(x) {
  agnes(OSPR_3day_norm[,1:7], method = x)$ac
}
sapply(m, ac) #ward is best for identifying strongest clustering structure
NbClust(OSPR_3day_norm[,1:7], method = "ward.D2", index = "all")$Best.nc # 6 clusters

#Create dendrogram and clusters
OSPR_3day_clust <- OSPR_3day_norm[,1:7] %>% dist %>% hclust(method = "ward.D2") %>% as.dendrogram
labels(OSPR_3day_clust) <- paste(as.character(OSPR_3day_norm[,8])[order.dendrogram(OSPR_3day_clust)])
SexColors<-c(M = "Blue", F = "Red")
labels_colors(OSPR_3day_clust) <-
   SexColors[sort_levels_values(
      as.numeric(OSPR_3day_norm[,18])[order.dendrogram(OSPR_3day_clust)]
   )]
OSPR_3day_clust<-color_branches(OSPR_3day_clust, k = 6, col = c("#593CD8", "#117733", "#EFD347", "#FF0000", "#E462C7"))
OSPR_3day_clust %>%
  set("labels_cex", 0.3) %>%      
  plot()

#Create a heatmap
OSPR_3day_clust <- OSPR_3day_norm[,1:7] %>% dist %>% hclust(method = "ward.D2") %>% as.dendrogram %>% ladderize
labels(OSPR_3day_clust) <- paste(as.character(OSPR_3day_norm[,8])
                                  [order.dendrogram(OSPR_3day_clust)])
OSPR_1day_clust<-color_branches(OSPR_3day_clust, k = 6, col = c("#593CD8", "#117733", "#EFD347", "#FF0000", "#E462C7"))

#Reorder the data set for labeling
target<-as.data.frame(labels(OSPR_3day_clust))
OSPR_3day_norm<-OSPR_1day_norm[ order(match(OSPR_3day_norm$trackId, 
                             target$`labels(OSPR_3day_clust)`)), ]
row_dend = dendsort(OSPR_3day_clust)
annotation<-rowAnnotation(df = OSPR_3day_norm[,13:19])

Heatmap(as.matrix(OSPR_3day_norm[,1:7]),
        col = rampcols,
        cluster_columns = F,
        name = "Scaled",
        column_title = "Migration Characteristics",
        column_title_side = "bottom",
        column_labels = c("Duration", "Total Distance", "Migration Speed", 
                          "Turn Speed","Turn Angle", "Sinuosity", 
                          "First Passage Time"),
        column_names_gp = gpar(fontsize = 8),
        column_names_rot = 90,
        cluster_rows = row_dend,
        row_labels = OSPR_3day_norm$trackId,
        row_title = "Migration Events",
        row_names_gp = gpar(fontsize = 2),
        row_dend_width = unit(3, "cm"),
        row_split = 3,
        border = TRUE
        )

```

#### PERMANOVA
```{r}
#add cluster labels to data 
cut_avg_1hour <- cutree(OSPR_1hour_clust, k = 2)
OSPR_1hour_norm<-mutate(OSPR_1hour_norm, cluster = cut_avg_1hour)

#test assumptions for PERMANOVA
dis_1hour <- vegdist(OSPR_1hour_norm[,1:7], method = "euclidean")
mod <- betadisper(dis_1hour, OSPR_1hour_norm$cluster, type = "centroid")
anova(mod) #does not meet assumptions and design is unbalanced. Dispersion are significantly different
plot(mod) #largest group has the most dispersion = PERMANOVA test will be overly conservative
adonis2(dis_1hour ~ OSPR_1hour_norm$cluster, method = "euclidean") #we still see a significant result so the two groups are different. 

OSPR_1hour_summary<-mutate(OSPR_1hour_summary, cluster = cut_avg_1hour)
clus1_1hour<-filter(OSPR_1hour_summary, cluster == 1)
clus1_mean<-lapply(clus1_1hour[,5:11], mean)

clus2_1hour<-filter(OSPR_1hour_summary, cluster == 2)
clus2_mean<-lapply(clus2_1hour[,5:11], mean)
cluster_mean<-rbind(clus1_mean, clus2_mean)
View(OSPR_1hour_summary)

ggplot(OSPR_1hour_summary, aes (x=as.factor(cluster), y = Start_Lat)) +
  geom_boxplot()
#turn speed and absolute turning angle do not look different
#displacement is different between the two groups
```

I will want to make a table of t-test p-values comparing the different variables to each other for each grouping, plus the two continuous explanatory values. 

I will want to create a table with the percentage composition of each categorical variable for each cluster. 

```{r}
#add cluster labels to data 
cut_avg_3hour <- cutree(OSPR_3hour_clust, k = 2)
OSPR_3hour_norm<-mutate(OSPR_3hour_norm, cluster = cut_avg_3hour)

#test assumptions for PERMANOVA
dis_3hour <- vegdist(OSPR_3hour_norm[,1:7], method = "euclidean")
mod <- betadisper(dis_3hour, OSPR_3hour_norm$cluster, type = "centroid")
anova(mod) #Meets the assumptions
plot(mod) #largest group has the most dispersion = PERMANOVA test will be overly conservative
adonis2(dis_3hour ~ OSPR_3hour_norm$cluster, method = "euclidean") #The groups are not different
```

```{r}
#add cluster labels to data 
cut_avg_1day <- cutree(OSPR_1day_clust, k = 2)
OSPR_1day_norm<-mutate(OSPR_1day_norm, cluster = cut_avg_1day)

#test assumptions for PERMANOVA
dis_1day <- vegdist(OSPR_1day_norm[,1:7], method = "euclidean")
mod <- betadisper(dis_1day, OSPR_1day_norm$cluster, type = "centroid")
anova(mod) #Meets the assumptions
plot(mod) #largest group has the most dispersion = PERMANOVA test will be overly conservative
adonis2(dis_1day ~ OSPR_1day_norm$cluster, method = "euclidean") #The groups are not different
```

```{r}
#add cluster labels to data 
cut_avg_3day <- cutree(OSPR_3day_clust, k = 6)
OSPR_3day_norm<-mutate(OSPR_3day_norm, cluster = cut_avg_3day)

#test assumptions for PERMANOVA
dis_3day <- vegdist(OSPR_3day_norm[,1:7], method = "euclidean")
mod <- betadisper(dis_3day, OSPR_3day_norm$cluster, type = "centroid")
anova(mod) #Does not meet assumptions
plot(mod) #largest group has the most dispersion = PERMANOVA test will be overly conservative
adonis2(dis_3day ~ OSPR_3day_norm$cluster, method = "euclidean") #The groups are not different
```


## References

* Help using the move package to download data from Movebank: <https://cran.r-project.org/web/packages/move/vignettes/browseMovebank.html> 
* Navigating and using data from the move package: <https://cran.r-project.org/web/packages/move/vignettes/move.html>
* Download a CSV file from github: <https://lokraj.me/post/download-github-data/>
* Github and RStudio interface: <https://rfortherestofus.com/2021/02/how-to-use-git-github-with-r/>
* Finding mode in R: <https://www.statology.org/mode-in-r/>
* migrateR Vignette: <https://github.com/dbspitz/migrateR/blob/master/migrateR%20vignette.pdf>
* Projections in R: <https://www.nceas.ucsb.edu/sites/default/files/2020-04/OverviewCoordinateReferenceSystems.pdf>
* adehabitatLT use (not the vignette): <http://www.r-gators.com/2018/01/31/wildlife-tracking-data-in-r/>
* Hopkins stat: <https://sushildeore99.medium.com/really-what-is-hopkins-statistic-bad1265df4b>, <https://stats.stackexchange.com/questions/332651/validating-cluster-tendency-using-hopkins-statistic>
* Basic HCA and Tanglegrams: <https://uc-r.github.io/hc_clustering>
* Dendrogram modification: <https://rpubs.com/JTK/hclust-color>
